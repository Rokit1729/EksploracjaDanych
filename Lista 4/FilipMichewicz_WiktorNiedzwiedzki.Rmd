---
title: "Raport - Zaawansowane metody klasyfikacji oraz analiza skupień – algorytmy grupujące i hierarchiczne"
author: "Filip Michewicz 282239  \n  Wiktor Niedźwiedzki 258882"
date: "18 czerwca 2025 Anno Domini"
output:
  pdf_document:
    number_sections: true
toc: true
lof: true
lot: true
header-includes:
  - \usepackage[OT4]{polski}
  - \usepackage[utf8]{inputenc}
  - \usepackage{graphicx}
  - \usepackage{float}
  - \renewcommand{\contentsname}{Spis treści}
  - \renewcommand{\listfigurename}{Spis wykresów}
  - \renewcommand{\listtablename}{Spis tabel}
  - \renewcommand{\figurename}{Wykres}
  - \renewcommand{\tablename}{Tabela}
  - \usepackage{xcolor}
  - \definecolor{ForestGreen}{rgb}{0.1333, 0.5451, 0.1333}
  - \definecolor{SteelBlue}{rgb}{0.2745, 0.5098, 0.7059}
  - \definecolor{Tomato}{rgb}{1.0, 0.3882, 0.2784}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  dpi = 1200,
  message = FALSE,
  warning = FALSE,
  error = TRUE,
  eval = TRUE,
  echo = FALSE,
  fig.align="center",
  fig.width = 7,
  fig.height = 4,
  fig.pos = "H",
  out.extra = '')
```

```{r biblioteki+zmienne_pomocnicze}
library(adabag)
library(ipred)
library(rpart)
library(rpart.plot)
library(mlbench)
library(randomForest)
library(HDclassif)
library(e1071)
library(knitr)
library(kableExtra)
library(stats)
library(clue)
library(cluster)
library(factoextra)
library(clValid)

start <- Sys.time()

data(wine)
data(Glass)
Glass.copy <- Glass

set.seed(21370)
```

```{r metryki}
metryki <- function(conf) {
  TP <- diag(conf)
  FP <- colSums(conf) - TP
  FN <- rowSums(conf) - TP
  TN <- sum(conf) - (TP + FP + FN)
  
  precision <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  recall <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  f1 <- ifelse((precision + recall) == 0, 0, 
               2 * precision * recall / (precision + recall))
  
  accuracy <- sum(TP) / sum(conf)
  accuracy_per_class <- (TP + TN) / (TP + TN + FP + FN)
  
  results <- data.frame(
    Accuracy = accuracy_per_class,
    Precision = precision,
    Recall = recall,
    F1_Score = f1
  )
  
  avg_metrics <- c(
    Accuracy = mean(accuracy_per_class), 
    Precision = mean(precision), 
    Recall = mean(recall), 
    F1_Score = mean(f1)
  )
  
  results <- rbind(results, avg_metrics)
  rownames(results)[nrow(results)] <- "Średnie"
  
  return(results)
}
```

\newpage

# Zaawansowane metody klasyfikacji

W pierwszej części zadania zastosujemy algorytmy *ensemble learning* (bagging,
boosting i random forest) w celu poprawy dokładności cech klasyfikacyjnych. 
W drugiej natomiast poznamy i ocenimy nową metodę klasyfikacji - metodę wektorów nośnych (SVM).

Zadanie zostanie wykonane na zbiorze danych *wine*, którego szczegółowy opis znajduje się w poprzednim raporcie.

## Rodziny klasyfikatorów/uczenie zespołowe

Wyróżniamy trzy algorytmy uczenia zespołowego (ang. ensemble learning):

* **Bagging** - generujemy B-bootstrapowych replikacji zbioru uczącego, na podstawie których tworzymy B klasyfikatorów. Następnie łączymy je w klasyfikator zagregowany, który przydziela dane cechy do klas za pomocą reguły "głosowania większości" (w przypadku remisu wybiera losowo). Każdy klasyfikator powstaje niezależnie (w sensie takim, że wyniki poprzednich nie mają wpływu na generowanie nowych).
* **Boosting** - podobnie jak w bagging, tworzymy klasyfikator zagregowany złożony z wielu pojedynczych klasyfikatorów. Jednak różnica jest taka, że klasyfikatory powstają sekwencyjnie. Na początku każda cecha w zbiorze ma przypisaną taką samą wagę. Z każdą kolejną iteracją natomiast waga zwiększa się dla uprzednio źle sklasyfikowanych przypadków.
* **Random forest** (dla drzew klasyfikacyjnych) - metoda podobna do bagging z tą różnicą, że klasyfikatory powstają na podstawie różnych m-elementowych podzbiorach cech (m mniejsze bądź równe wszystkim cechom).

```{r wczytanie_win}
colnames(wine) <- c(
  "Gatunek", "Alkohol", "Kwas_mlekowy", "Popiół", "Zasadowość_popiołu", 
  "Magnez", "Fenole_ogółem", "Flawonoidy", 
  "Fenole_nieflawonoidowe", "Proantocyjanidyny",
  "Koloru", "Barwa", "OD280_OD315", "Prolina"
)
wine$Gatunek <- as.factor(wine$Gatunek)
wine$Magnez <- as.numeric(wine$Magnez)
wine$Prolina <- as.numeric(wine$Prolina)

col <- sapply(wine, is.numeric)
wine_scaled <- wine
wine_scaled[col] <- scale(wine[col])
```

Na wykresie przedstawiono pojedyńcze drzewo klasyfikacyjne.

```{r drzewo_klasyfikacyjne, fig.cap="Pojedyńcze drzewo klasyfikacyjne", cache = TRUE}
mypredict.rpart <- function(object, newdata)  predict(object, newdata=newdata, type="class")

mypredict.boost <- function(object, newdata) as.factor(predict(object, newdata=newdata)$class)

est <- "632plus"
K = 10

tree_model <- rpart(Gatunek ~ ., data = wine, method = "class")
rpart.plot(tree_model, type = 2, extra = 104, fallen.leaves = TRUE)

error.tree <- (errorest(Gatunek ~ ., data = wine,
                       model = rpart,
                       predict = mypredict.rpart,
                       estimator = est,
                       est.para = control.errorest(nboot = K)))$error
```

Błąd estymowany metodą bootstrap .632+ wynosi `r round(error.tree*100, 2)`%. Na jego podstawie określimy poprawę modelu po zastosowaniu metod uczenia zespołowego. 

W tej części analizy do oceny wydajności modelu zostanie wykorzystana wyłącznie metoda .632+, ponieważ koryguje ona obciążenie estymatora (bias) i dostarcza bardziej wiarygodnej oceny błędu generalizacji, zwłaszcza przy ryzyku przeuczenia i ograniczonej liczbie próbek.


``` {r drzewa-klasyfikacyjne, cache = TRUE}
mypredict.rpart <- function(object, newdata)  predict(object, newdata=newdata, type="class")

mypredict.boost <- function(object, newdata) as.factor(predict(object, newdata=newdata)$class)

lista <- list()
B.vector <- c(1, 5, 10, 20, 30, 40, 50, 100)

error.bagging <- 0
error.randomForest <- 0
error.boosting <- 0

for(b in B.vector){
  
  error.bagging <- (errorest(Gatunek~., data = wine, model = bagging,
                                            estimator = est,
                                            est.para = control.errorest(nboot = K),
                                            nbagg = b))$error
    
  error.randomForest <- (errorest(Gatunek~., data = wine, model = randomForest,
                                                      estimator = est,
                                                      est.para = control.errorest(nboot = K),
                                                      model.args = list(ntree = b)))$error
    
  error.boosting <- (errorest(Gatunek~., data = wine, model = boosting,
                                              predict = mypredict.boost,
                                              estimator = est,
                                              est.para = control.errorest(nboot = K),
                                              model.args = list(mfinal = b)))$error
  
  poprawa <- c((error.tree - error.bagging)/error.tree*100,
               (error.tree - error.randomForest)/error.tree*100,
              (error.tree - error.boosting)/error.tree*100)
  
  lista[[as.character(b)]] <- poprawa

}

matrix <- do.call(cbind, lista)
rownames(matrix) <- c("Bagging", "Random Forest", "Boosting")
```

```{r}
kable(matrix,
  caption = "Średnia poprawa dokładności klasyfikacji za pomocą drzewa klasyfikacyjnego, z podziałem na algorytmy uczenia zespołowego oraz liczbę replikacji", 
  digits = 2) %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

## Metoda wektorów nośnych (SVM)

W tej części przeprowadzona będzie klasyfikacja na podstawie metody wektorów nośnych, z podziałem na różne funkcje jądrowe.

Metoda SVM jest jedną z najczęściej stosowanych technik uczenia maszynowego w zadaniach klasyfikacyjnych. Jej podstawowym celem jest wyznaczenie hiperpłaszczyzny maksymalnie oddzielającej obserwacje należące do różnych klas, przy jednoczesnym maksymalizowaniu marginesu między klasami.

Dzięki zastosowaniu funkcji jądrowych (kernel functions), SVM umożliwia również skuteczną klasyfikację danych nieliniowo separowalnych poprzez odwzorowanie ich do przestrzeni o wyższej liczbie wymiarów. W niniejszej analizie zostaną porównane różne funkcje jądrowe, w tym liniowa, wielomianowa oraz radialna (RBF), w kontekście ich wpływu na jakość klasyfikacji.

```{r super-uber-duper-ultra-zajebiste-funkcje, cache = TRUE}

C <- 10^(-3:3) #kara
gamma <- round(seq(from = .01, to = 10, length.out = 10), 2)

#NIE działają dla kernel = "linear"

#Wielokrotny podział
kernel.type <- function(K = 10, size = 2/3,
                        scale = FALSE, kernel){
  
  df <- as.data.frame(matrix(NA, nrow = length(C), ncol = length(gamma)))
  
  rownames(df) <- as.character(C)
  colnames(df) <- as.character(gamma)
  
  for(c in C){
    
    for(g in gamma){
      
      accuracy <- 0
      
      for(i in 1:K){
        
        id.learn <- sample(seq_len(nrow(wine)),
                           size = floor(nrow(wine) * size))
        
        if(scale==TRUE){
          train.set <- wine_scaled[id.learn, ]
          test.set <- wine_scaled[-id.learn, ]
        }
        else{
          train.set <- wine[id.learn, ]
          test.set <- wine[-id.learn, ]
        }
        
        svm <- svm(Gatunek ~ ., data=train.set, kernel = kernel,
                   gamma = g, cost = c)
        
        prediction <- predict(svm, newdata=test.set)
        prediction <- table(prediction, test.set$Gatunek)
        
        accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
      }
      
      df[as.character(c), as.character(g)] <- accuracy/K*100
    
    }
  }
  
  return(df)
}

#Cross-validation
kernel.type.cv <- function(K = 10, scale = FALSE, kernel){
  
  df <- as.data.frame(matrix(NA, nrow = length(C), ncol = length(gamma)))
  
  rownames(df) <- as.character(C)
  colnames(df) <- as.character(gamma)
  
  folds <- sample(rep(seq_len(K), length.out = nrow(wine)))
  
  for(c in C){
    
    for(g in gamma){
      
      accuracy <- 0
      
      for(i in 1:K){
        
        if(scale == TRUE){
          train.set <- wine_scaled[folds != i, ]
          test.set <- wine_scaled[folds == i, ]
        }
        else{
          train.set <- wine[folds != i, ]
          test.set <- wine[folds == i, ]
        }
        
        svm <- svm(Gatunek ~ ., data=train.set, kernel = kernel,
                   gamma = g, cost = c)
        
        prediction <- predict(svm, newdata=test.set)
        prediction <- table(prediction, test.set$Gatunek)
        
        accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
      }
      
      df[as.character(c), as.character(g)] <- accuracy/K*100
    
    }
  }
  
  return(df)
}

#Bootstrap
kernel.type.bs <- function(K = 10, size = 2/3, scale = FALSE, kernel){
  
  df <- as.data.frame(matrix(NA, nrow = length(C), ncol = length(gamma)))
  
  rownames(df) <- as.character(C)
  colnames(df) <- as.character(gamma)
  
  for(c in C){
    
    for(g in gamma){
      
      accuracy <- 0
      
      for(i in 1:K){
        
        id.learn <- sample(seq_len(nrow(wine)),
                           size = floor(nrow(wine) * size),
                           replace = TRUE)
        
        if(scale == TRUE){
          train.set <- wine_scaled[id.learn, ]
          test.set <- wine_scaled[-id.learn, ]
        }
        else{
          train.set <- wine[id.learn, ]
          test.set <- wine[-id.learn, ]
        }
        
        svm <- svm(Gatunek ~ ., data=train.set, kernel = kernel,
                   gamma = g, cost = c)
        
        prediction <- predict(svm, newdata=test.set)
        prediction <- table(prediction, test.set$Gatunek)
        
        accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
      }
      
      df[as.character(c), as.character(g)] <- accuracy/K*100
    
    }
  }
  
  return(df)
}

```

### Jądro liniowe

Przeanalizowano skuteczność klasyfikacyjną z zastosowaniem **jądra liniowego**, zarówno **bez skalowania danych**, jak i **po ich skalowaniu**.

Porównanie wyników dla obu wariantów (ze skalowaniem i bez) pozwala ocenić wpływ przeskalowania zmiennych na jakość klasyfikacji. Ponieważ SVM opiera się na obliczeniach odległości i iloczynów skalarnych, skalowanie danych może znacząco wpłynąć na działanie algorytmu, szczególnie gdy zmienne wejściowe różnią się skalą lub jednostką.

```{r, cache = TRUE}

df <- matrix(NA, nrow = 3, ncol = length(C))

#Wielokrotny podział
col <- 0
for(c in C){
  
  col <- col + 1
  
  accuracy <- 0
  for(i in seq_len(K)){
    
    id.learn <- sample(seq_len(nrow(wine)), size = floor(nrow(wine) * 2/3))
    train.set <- wine[id.learn, ]
    test.set <- wine[-id.learn, ]
    
    svm <- svm(Gatunek ~ ., data=train.set, kernel = "linear", cost = c)
    
    prediction <- predict(svm, newdata=test.set)
    prediction <- table(prediction, test.set$Gatunek)
    
    accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
  }
  
  df[1, col] <- accuracy/K*100
}

#Cross-validation
folds <- sample(rep(seq_len(K), length.out = nrow(wine)))
col <- 0

for(c in C){
  
  col <- col + 1
  
  accuracy <- 0
  for(i in seq_len(K)){
    
    train.set <- wine[folds == i, ]
    test.set <- wine[folds != i, ]
    
    svm <- svm(Gatunek ~ ., data=train.set, kernel = "linear", cost = c)
    
    prediction <- predict(svm, newdata=test.set)
    prediction <- table(prediction, test.set$Gatunek)
    
    accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
  }
  
  df[2, col] <- accuracy/K*100
}

#Bootstrap
col <- 0

for(c in C){
  
  col <- col + 1
  
  accuracy <- 0
  for(i in seq_len(K)){
    
    id.learn <- sample(seq_len(nrow(wine)), size = floor(nrow(wine) * 2/3),
                       replace = TRUE)

    train.set <- wine[id.learn, ]
    test.set <- wine[-id.learn, ]
    
    svm <- svm(Gatunek ~ ., data=train.set, kernel = "linear", cost = c)
    
    prediction <- predict(svm, newdata=test.set)
    prediction <- table(prediction, test.set$Gatunek)
    
    accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
  }
  
  df[3, col] <- accuracy/K*100
}

df <- rbind(df, colMeans(df))
df <- as.data.frame(df)
rownames(df) <- c("Wielokrotny podział",
                  "Cross-validation",
                  "Bootstrap",
                  "Średnio")
colnames(df) <- as.character(C)
```

```{r}
kable(df, caption = "Jądro liniowe - bez skalowania", digits = 2) %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}

df <- matrix(NA, nrow = 3, ncol = length(C))

#Wielokrotny podział
col <- 0
for(c in C){
  
  col <- col + 1
  
  accuracy <- 0
  for(i in seq_len(K)){
    
    id.learn <- sample(seq_len(nrow(wine)), size = floor(nrow(wine) * 2/3))
    
    train.set <- wine_scaled[id.learn, ]
    test.set <- wine_scaled[-id.learn, ]
    
    svm <- svm(Gatunek ~ ., data=train.set, kernel = "linear", cost = c)
    
    prediction <- predict(svm, newdata=test.set)
    prediction <- table(prediction, test.set$Gatunek)
    
    accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
  }
  
  df[1, col] <- accuracy/K*100
}

#Cross-validation
folds <- sample(rep(seq_len(K), length.out = nrow(wine)))
col <- 0

for(c in C){
  
  col <- col + 1
  
  accuracy <- 0
  for(i in seq_len(K)){
    
    train.set <- wine_scaled[folds == i, ]
    test.set <- wine_scaled[folds != i, ]
    
    svm <- svm(Gatunek ~ ., data=train.set, kernel = "linear", cost = c)
    
    prediction <- predict(svm, newdata=test.set)
    prediction <- table(prediction, test.set$Gatunek)
    
    accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
  }
  
  df[2, col] <- accuracy/K*100
}

#Bootstrap
col <- 0

for(c in C){
  
  col <- col + 1
  
  accuracy <- 0
  for(i in seq_len(K)){
    
    id.learn <- sample(seq_len(nrow(wine)), size = floor(nrow(wine) * 2/3),
                       replace = TRUE)
    
    train.set <- wine_scaled[id.learn, ]
    test.set <- wine_scaled[-id.learn, ]
    
    svm <- svm(Gatunek ~ ., data=train.set, kernel = "linear", cost = c)
    
    prediction <- predict(svm, newdata=test.set)
    prediction <- table(prediction, test.set$Gatunek)
    
    accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
  }
  
  df[3, col] <- accuracy/K*100
}

df <- rbind(df, colMeans(df))
df <- as.data.frame(df)
rownames(df) <- c("Wielokrotny podział",
                  "Cross-validation",
                  "Bootstrap",
                  "Średnio")
colnames(df) <- as.character(C)
```

```{r}
kable(df, caption = "Jądro liniowe - ze skalowaniem", digits = 2) %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

Z analizy Tabeli 2. oraz Tabeli 3. wynika, że optymalną wartością parametru **C** w klasyfikacji SVM z jądrem liniowym jest **0.1**. Dla tej wartości obserwuje się najwyższą średnią skuteczność klasyfikacji zarówno bez skalowania, jak i po skalowaniu danych. Ponadto, zastosowanie skalowania cech nieznacznie poprawia wyniki, co wskazuje na korzystny wpływ normalizacji na efektywność modelu.

Wyższe wartości parametru **C** nie przekładają się na istotną poprawę skuteczności klasyfikacji, a w niektórych przypadkach powodują nawet jej nieznaczny spadek. Wynika to z faktu, że zbyt duża wartość **C** powoduje nadmierne dopasowanie modelu do danych treningowych (overfitting). W konsekwencji, mimo że model stara się minimalizować błędy na zbiorze treningowym, jego efektywność na danych testowych nie ulega poprawie, co potwierdzają uzyskane wyniki.

### Jądro wielomianowe

```{r, cache = TRUE}
kable(kernel.type(kernel="polynomial"), digits = 2,
      caption = "Jądro wielomianowe - wielokrotny podział, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
dataFrame <- kernel.type(scale = TRUE, kernel="polynomial")

kable(dataFrame, digits = 2,
      caption = "Jądro wielomianowe - wielokrotny podział, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.cv(kernel="polynomial"), digits = 2,
      caption = "Jądro wielomianowe - cross-validation, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.cv(scale = TRUE, kernel="polynomial"), digits = 2,
      caption = "Jądro wielomianowe - cross-validation, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.bs(kernel="polynomial"), digits = 2,
      caption = "Jądro wielomianowe - bootstrap, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.bs(scale = TRUE, kernel="polynomial"), digits = 2,
      caption = "Jądro wielomianowe - bootstrap, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
best_gamma <- 0
best_C <- 0
kandydat <- 0

for(i in C){
  for(j in gamma){
    cell <- dataFrame[as.character(i), as.character(j)]
    if(cell > kandydat){
      best_gamma <- j
      best_C <- i
      kandydat <- cell
    }
  }
}

degree <- 2:7
df <- as.data.frame(matrix(NA, nrow=1, ncol=length(degree)))
rownames(df) <- "Dokładność"
colnames(df) <- as.character(degree)

K <- 10
for(d in degree){
  
  accuracy <- 0
  
  for(i in seq_len(K)){
    
    id.learn <- sample(seq_len(nrow(wine)), size = floor(nrow(wine) * 2/3))
    train.set <- wine_scaled[id.learn, ]
    test.set <- wine_scaled[-id.learn, ]
    
    svm <- svm(Gatunek ~ ., data=train.set, kernel = "polynomial",
               degree = d, gamma = best_gamma, cost = best_C)
    
    prediction <- predict(svm, newdata=test.set)
    prediction <- table(prediction, test.set$Gatunek)
    
    accuracy <- accuracy + sum(diag(prediction))/sum(prediction)
  
  }
  
  df[1, as.character(d)] <- accuracy/K*100

}
```

Najlepsza gamma: **`r best_gamma`**, najlepsza kara: **`r best_C`**. Robimy dla danych po standaryzacji, bo tak i chuj.

Badamy tylko na podstawie wielokrotnego podziału, bo tak i chuj również.

```{r}
kable(df, digits = 2,
      caption = "Badanie wpływu stopnia wielomianu na dokładność - wielokrotny podział, najbardziej dokładna kombinacja gammy i kary dla opcji default (stopień 3")
```

### Jądro radialne

```{r, cache = TRUE}
kable(kernel.type.cv(kernel="radial"), digits = 2,
      caption = "Jądro radialne - wielokrotny podział, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.cv(scale = TRUE, kernel="radial"), digits = 2,
      caption = "Jądro radialne - wielokrotny podział, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.cv(kernel="radial"), digits = 2,
      caption = "Jądro radialne - cross-validation, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.cv(scale = TRUE, kernel="radial"), digits = 2,
      caption = "Jądro radialne - cross-validation, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.bs(kernel="radial"), digits = 2,
      caption = "Jądro radialne - bootstrap, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.bs(scale= TRUE, kernel="radial"), digits = 2,
      caption = "Jądro radialne - bootstrap, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

### Jądro sigmoidalne

```{r, cache = TRUE}
kable(kernel.type(kernel="sigmoid"), digits = 2,
      caption = "Jądro sigmoidalne - wielokrotny podział, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type(scale = TRUE, kernel="sigmoid"), digits = 2,
      caption = "Jądro sigmoidalne - wielokrotny podział, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.cv(kernel="sigmoid"), digits = 2,
      caption = "Jądro sigmoidalne - cross-validation, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.cv(scale = TRUE, kernel="sigmoid"), digits = 2,
      caption = "Jądro sigmoidalne - cross-validation, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.bs(kernel="sigmoid"), digits = 2,
      caption = "Jądro sigmoidalne - bootstrap, bez skalowania") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

```{r, cache = TRUE}
kable(kernel.type.bs(scale = TRUE, kernel="sigmoid"), digits = 2,
      caption = "Jądro sigmoidalne - bootstrap, ze skalowaniem") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")
```

elo

## Wnioski

e

\newpage

# Analiza skupień – algorytmy grupujące i hierarchiczne

W tym zadaniu zastosujemy i porównamy ze sobą metody analizy skupień - k-średnich i PAM jako algorytmy grupujące, oraz AGNES - algorytm hierarhiczny.

Zadanie zostanie wykonane na zbiorze danych *wine*, którego szczegółowy opis znajduje się w poprzednim raporcie.

To zadanie zostanie wykonane już na innym danych, którymi będzie zbiór *glass*.

## Charakterystyka danych

Zbiór danych glass zawiera **`r nrow(Glass)`** przypadków sześciu rodzajów szkła oraz **`r ncol(Glass)`** cech. Liczba brakujących
danych wynosi **`r sum(is.na(Glass))`**.

Znaczenie poszczególnych cech oraz ich typ przedstawiono w tabeli 23.

```{r, cache=TRUE}
df_table <- data.frame(
  Typ = sapply(Glass, class),
  Opis = c("Współczynnik załamania światła",
           "Zawartość azotu (procent wagowy w odpowiednim tlenku, podobnie jak atrybuty 3-9)",
           "Zawartość magnezu",
           "Zawartość aluminium",
           "Zawartość krzemu",
           "Zawartość potasu",
           "Zawartość wapnia",
           "Zawartość baru",
           "Zawartość żelaza",
           "Klasa (typ szkła: 1, 2, 3, 5, 6, 7)"
           )
)

kable(df_table,
      col.names = c("Zmienna", "Typ", "Opis"),
      caption = "Opis zmiennych w zbiorze danych wine") %>%
  kable_styling(latex_options = c("striped", "hold_position", "repeat_header"), 
                repeat_header_text = "(kontynuacja)",
                stripe_color = "#B0B0B0")

```

```{r, cache=TRUE}
sumy <- rowSums(Glass[-c(1, 10)])
```

W poszczególnych przypadkach sumy procentów wagowych znajdują się w zakresie `r min(sumy)`-`r max(sumy)`. Nadmiar spowodowany jest najprawdopodobniej przez błędy przy zaokrąglaniu do dwóch miejsc po przecinku. Niedomiar natomiast może być spowodowany przez zawartość innych pierwiastków chemicznych, niezawartych w zbiorze.

```{r, cache=TRUE, fig.cap="Liczność poszczególnych typów szkła"}
etykiety <- Glass$Type

K <- length(unique(etykiety))
n <- length(etykiety)
p <- length(Glass) - 1

ggplot(data.frame(etykiety), aes(x = etykiety, fill = etykiety)) +
  geom_bar() +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) + 
  labs(x = "Gatunek wina", y = "Liczba wystąpień") +
  scale_fill_manual(values = c("tomato", "darkgoldenrod1", "darkgreen",
                               "steelblue","darkblue", "deeppink2")) +
  theme_minimal() +
  theme(legend.position = "none")
```

Z Wykresu 1. można odczytać, że liczba obserwacji poszczególnych klas w zbiorze danych jest bardzo zróżnicowana. Siedemdziesiąt obserwacji lub więcej posiadają typy 1. oraz 2. (co stanowi `r round((70+76)/214*100, 2)`% danych), reszta już po mniej niż 30 obserwacji.

```{r, fig.cap="Wykres pudełkowy, zmienne bez standaryzacji"}
boxplot(Glass[-10], las=2, col="tomato")
```

KURWA STANDARYZACJA MACHEN

```{r, fig.cap="Wykres pudełkowe, po standaryzacji"}
Glass[-10] <- scale(Glass[-10])
glass <- Glass[-10]

k <- length(levels(Glass$Type))

boxplot(glass, las=2, col="tomato") #Teraz zajebiście
```

Teraz jest zajebiście

```{r, fig.cap="Wizualizacja danych, PCA"}
pca_result <- prcomp(glass)
pca_summary <- summary(pca_result)$importance

xlab1 <- paste0("PC1 (", round(pca_summary[2, 1]*100, 2), "%)")
ylab1 <- paste0("PC2 (", round(pca_summary[2, 2]*100, 2), "%)")

plot(pca_result$x[, 1], pca_result$x[, 2],
     xlab = xlab1, ylab = ylab1,
     col = Glass$Type)
```

Chuja widać, ciekawe kto wybrał ten zbiór?

## Wyniki grupowania

Przeprowadzamy dla rzeczywistej liczby etykiet, która wynosi **`r k`**.

### k-średnie

```{r, fig.cap="PCA, kolory - rzeczywiste, kształt - wyniki"}
kmeans.k3 <- kmeans(glass, centers = k, iter.max = 10)
wyniki <- kmeans.k3$cluster

plot(pca_result$x[, 1], pca_result$x[, 2], xlab = xlab1, ylab = ylab1,
     col = Glass$Type, pch = wyniki)
```

Gównianie mu poszło

```{r, fig.cap="Wykres RI od Na, aby pokazać gdzie są wyznaczone centra skupień"}
plot(glass$RI, glass$Na, xlab = "RI", ylab = "Na",
     col = Glass$Type, pch = wyniki)
points(kmeans.k3$centers[,c("RI", "Na")], pch=16, cex=1.5, col=1:6)
```

Centra wywalone w kosmos, ale fajnie

```{r}
matrix <- table(wyniki, Glass$Type)

#Najlepsze dopasowanie
mapping <- solve_LSAP(matrix, maximum = TRUE)
wyniki1 <- mapping[wyniki]

matrix  <- table(wyniki1, Glass$Type)
rownames(matrix) <- as.character(c(1:3, 5:7))
colnames(matrix) <- as.character(c(1:3, 5:7))

kable(matrix , caption = "Macierz błędów; metoda k-średnich")
```

Dokładność (macierz): `r round(sum(diag(matrix))/sum(matrix)*100, 2)`%.

Dokładność (matchClasses, "exact"): `r round(compareMatchedClasses(wyniki, Glass$Type, method="exact")$diag*100, 2)`%.

### Partitioning Around Medoids (PAM)

```{r, fig.cap="coś"}
glass.conf_mat <- daisy(glass)

glass.pam7 <- pam(x=glass.conf_mat, diss=TRUE, k=k)

wyniki <- glass.pam7$clustering

Glass.copy$PAM <- wyniki

plot(pca_result$x[, 1], pca_result$x[, 2], xlab = xlab1, ylab = ylab1,
     col = wyniki, pch = as.numeric(Glass$Type))
```

Też słabo

```{r, fig.cap="coś, z medoidami"}
medoids <- glass[glass.pam7$id.med, ]

plot(glass$RI, glass$Na, xlab = "RI", ylab = "Na",
     col = wyniki, pch = as.numeric(Glass$Type))
points(medoids[,c("RI", "Na")], pch=16, cex=1.5, col=1:6)
```

Meh

```{r}
kable(Glass.copy[glass.pam7$id.med, ], caption="Dane medoidów, k=6")
```

```{r}
matrix <- table(wyniki, Glass$Type)

#Najlepsze dopasowanie
mapping <- solve_LSAP(matrix , maximum = TRUE)
wyniki1 <- mapping[wyniki]

conf_mat <- table(wyniki1, Glass$Type)
rownames(matrix) <- as.character(c(1:3, 5:7))
colnames(matrix) <- as.character(c(1:3, 5:7))

kable(matrix, caption = "Macierz błędów; metoda k-średnich")
```

Dokładność: `r round(sum(diag(matrix))/sum(matrix)*100, 2)`%.

Dokładność (matchClasses, "exact"): `r round(compareMatchedClasses(wyniki, Glass$Type, method="exact")$diag*100, 2)`%.

Gorzej niż k-średnie *shocked emoji*.

### Agglomerative Nesting (AGNES)

#### Najbliższy sąsiad

\newpage

```{r, fig.cap="AGNES: single linkage"}
glass.agnes.single <- agnes(x = glass.conf_mat,
                            diss = TRUE,
                            method = "single")

fviz_dend(glass.agnes.single, cex=0.4, k = k)
```

```{r}
wyniki <- cutree(glass.agnes.single, k = k)

matrix <- table(wyniki, Glass$Type)

#Najlepsze dopasowanie
mapping <- solve_LSAP(matrix , maximum = TRUE)
wyniki1 <- mapping[wyniki]

conf_mat <- table(wyniki1, Glass$Type)
rownames(matrix) <- as.character(c(1:3, 5:7))
colnames(matrix) <- as.character(c(1:3, 5:7))

kable(matrix, caption = "Macierz błędów; agnes, najbliższy sąsiad")
```

Dokładność: `r round(sum(diag(matrix))/sum(matrix)*100, 2)`%.

Dokładność (matchClasses, "exact"): `r round(compareMatchedClasses(wyniki, Glass$Type, method="exact")$diag*100, 2)`%.

#### Najdalszy sąsiad

\newpage

```{r, fig.cap="AGNES: complete linkage"}
glass.agnes.complete <- agnes(x = glass.conf_mat,
                            diss = TRUE,
                            method = "complete")

fviz_dend(glass.agnes.complete, cex=0.4, k = k)
```

```{r}
wyniki <- cutree(glass.agnes.complete, k = k)

matrix <- table(wyniki, Glass$Type)

#Najlepsze dopasowanie
mapping <- solve_LSAP(matrix , maximum = TRUE)
wyniki1 <- mapping[wyniki]

conf_mat <- table(wyniki1, Glass$Type)
rownames(matrix) <- as.character(c(1:3, 5:7))
colnames(matrix) <- as.character(c(1:3, 5:7))

kable(matrix, caption = "Macierz błędów; agnes, najdalszy sąsiad")
```

Dokładność: `r round(sum(diag(matrix))/sum(matrix)*100, 2)`%.

Dokładność (matchClasses, "exact"): `r round(compareMatchedClasses(wyniki, Glass$Type, method="exact")$diag*100, 2)`%.

#### Średnia odległość

\newpage

```{r, fig.cap="AGNES: average linkage"}
glass.agnes.average <- agnes(x = glass.conf_mat,
                            diss = TRUE,
                            method = "average")

fviz_dend(glass.agnes.average, cex=0.4, k = k)
```

```{r}
wyniki <- cutree(glass.agnes.average, k = k)

matrix <- table(wyniki, Glass$Type)

#Najlepsze dopasowanie
mapping <- solve_LSAP(matrix , maximum = TRUE)
wyniki1 <- mapping[wyniki]

conf_mat <- table(wyniki1, Glass$Type)
rownames(matrix) <- as.character(c(1:3, 5:7))
colnames(matrix) <- as.character(c(1:3, 5:7))

kable(matrix, caption = "Macierz błędów; agnes, średnia odległość")
```

Dokładność: `r round(sum(diag(matrix))/sum(matrix)*100, 2)`%.

Dokładność (matchClasses, "exact"): `r round(compareMatchedClasses(wyniki, Glass$Type, method="exact")$diag*100, 2)`%.

### Divisive clustering (DIANA)

#### Odległość euklidesowa

\newpage

```{r, fig.cap="AGNES: average linkage"}
glass.agnes.euclidean <- diana(x = glass.conf_mat,
                            diss = TRUE,
                            metric = "euclidean")

fviz_dend(glass.agnes.euclidean, cex=0.4, k = k)
```

```{r}
wyniki <- cutree(glass.agnes.euclidean, k = k)

matrix <- table(wyniki, Glass$Type)

#Najlepsze dopasowanie
mapping <- solve_LSAP(matrix , maximum = TRUE)
wyniki1 <- mapping[wyniki]

conf_mat <- table(wyniki1, Glass$Type)
rownames(matrix) <- as.character(c(1:3, 5:7))
colnames(matrix) <- as.character(c(1:3, 5:7))

kable(matrix, caption = "Macierz błędów; agnes, średnia odległość")
```

Dokładność: `r round(sum(diag(matrix))/sum(matrix)*100, 2)`%.

Dokładność (matchClasses, "exact"): `r round(compareMatchedClasses(wyniki, Glass$Type, method="exact")$diag*100, 2)`%.

#### Odległość Manhattan (taksówkowa)

\newpage

```{r, fig.cap="AGNES: average linkage"}
glass.agnes.manhattan <- diana(x = glass.conf_mat,
                            diss = TRUE,
                            metric = "manhattan")

fviz_dend(glass.agnes.manhattan, cex=0.4, k = k)
```

```{r}
wyniki <- cutree(glass.agnes.manhattan, k = k)

matrix <- table(wyniki, Glass$Type)

#Najlepsze dopasowanie
mapping <- solve_LSAP(matrix , maximum = TRUE)
wyniki1 <- mapping[wyniki]

conf_mat <- table(wyniki1, Glass$Type)
rownames(matrix) <- as.character(c(1:3, 5:7))
colnames(matrix) <- as.character(c(1:3, 5:7))

kable(matrix, caption = "Macierz błędów; agnes, średnia odległość")
```

Dokładność: `r round(sum(diag(matrix))/sum(matrix)*100, 2)`%.

Dokładność (matchClasses, "exact"): `r round(compareMatchedClasses(wyniki, Glass$Type, method="exact")$diag*100, 2)`%.

## Ocena jakości grupowania i wizualizacja najlepszych wyników

### Ocena

Legenda:

* 1 - kmeans,
* 2 - PAM,
* 3 - AGNES,
* 4 - DIANA.

```{r, fig.cap="coś", cache = TRUE}
metody <- c("kmeans", "pam", "agnes", "diana")
K.zakres <- 2:k

internal.validation <- clValid(glass,
                               nClust = K.zakres,
                               clMethods = metody,
                               validation = "internal")

measures <- internal.validation@measures

#Silhouette
silhouette <- data.frame("Kmeans" = measures[3, , 1],
                         "PAM" = measures[3, , 2],
                         "AGNES" = measures[3, , 3],
                         "DIANA" = measures[3, , 4],
                         "K" = 2:k)

#Connectivity
connectivity <- data.frame("Kmeans" = measures[1, , 1],
                           "PAM" = measures[1, , 2],
                           "AGNES" = measures[1, , 3],
                           "DIANA" = measures[1, , 4],
                           "K" = 2:k)

#Dunn
dunn <- data.frame("Kmeans" = measures[2, , 1],
                   "PAM" = measures[2, , 2],
                   "AGNES" = measures[2, , 3],
                   "DIANA" = measures[2, , 4],
                   "K" = 2:k)
```

```{r, fig.cap="Connectivity", cache = TRUE}
max <- max(connectivity[-5])

plot(connectivity$K, connectivity$Kmeans,
     type = "b", lty = 1, col = 1, lwd = 2,  pch=paste(1),
     xlab = "Liczba skupień", ylab = "Wskaźnik connectivity",
     ylim = c(0, max), las=1)

for(i in 2:4){
  lines(connectivity$K, as.vector(connectivity[, i]),
        type = "b", lty = i, col = i, lwd = 2, pch=paste(i))
}

legend("bottomright", legend = c("1", "2", "3", "4"), col = 1:4, lty = 1:4, pch = paste(1:4), lwd = 2)
```

Connectivity - im mniejszy, tym lepszy:

* kmeans - 2,
* PAM - 2,
* AGNES - 2 (najlepszy),
* DIANA - 3.

```{r, fig.cap="Dunn", cache = TRUE}
max <- max(dunn[-5])

plot(dunn$K, dunn$Kmeans,
     type = "b", lty = 1, col = 1, lwd = 2,  pch=paste(1),
     xlab = "Liczba skupień", ylab = "Wskaźnik Dunn'a",
     ylim = c(0, max), las=1)

for(i in 2:4){
  lines(dunn$K, as.vector(dunn[, i]),
        type = "b", lty = i, col = i, lwd = 2, pch=paste(i))
}

legend("bottomright", legend = c("1", "2", "3", "4"), col = 1:4, lty = 1:4, pch = paste(1:4), lwd = 2)
```

Dunn - im większy, tym lepszy:

* kmeans - 2,
* PAM - 2,
* AGNES - 2 (najlepszy),
* DIANA - 3.

```{r, fig.cap="Silhouette"}
plot(silhouette$K, silhouette$Kmeans,
     type = "b", lty = 1, col = 1, lwd = 2,  pch=paste(1),
     xlab = "Liczba skupień", ylab = "Indeks silhouette",
     ylim = c(0, 1), las=1)

for(i in 2:4){
  lines(silhouette$K, as.vector(silhouette[, i]),
        type = "b", lty = i, col = i, lwd = 2, pch=paste(i))
}

legend("bottomright", legend = c("1", "2", "3", "4"), col = 1:4, lty = 1:4, pch = paste(1:4), lwd = 2)
```

Dunn - im większy, tym lepszy:

* kmeans - 2,
* PAM - 2,
* AGNES - 2 (najlepszy),
* DIANA - 2.

### Wizualizacja

#### k-średnie

\newpage

```{r, fig.cap="PCA, kolory - rzeczywiste, kształt - wyniki, k=2"}
kmeans.k3 <- kmeans(glass, centers = 2, iter.max = 10)
wyniki <- kmeans.k3$cluster

plot(pca_result$x[, 1], pca_result$x[, 2], xlab = xlab1, ylab = ylab1,
     pch = wyniki+1, col = wyniki)
```

Gównianie mu poszło

```{r, fig.cap="Wykres RI od Na, aby pokazać gdzie są wyznaczone centra skupień, k=2"}
plot(glass$RI, glass$Na, xlab = "RI", ylab = "Na", pch = wyniki+1,
     col = wyniki)
points(kmeans.k3$centers[,c("RI", "Na")], pch = 16, cex = 1.5, col = 1:2)
```

Centra wywalone w kosmos, ale fajnie

Dokładność (matchedClasses): `r round(compareMatchedClasses(wyniki, Glass$Type)$diag*100, 2)`%.

#### PAM

\newpage

```{r, fig.cap="coś, k=2"}
glass.pam7 <- pam(x=glass.conf_mat, diss=TRUE, k=2)

wyniki <- glass.pam7$clustering

Glass.copy$PAM <- wyniki

plot(pca_result$x[, 1], pca_result$x[, 2], xlab = xlab1, ylab = ylab1,
     col = wyniki, pch = wyniki+1)
```

Też słabo

```{r, fig.cap="coś, z medoidami, k=2"}
medoids <- glass[glass.pam7$id.med, ]

plot(glass$RI, glass$Na, xlab = "RI", ylab = "Na",
     col = wyniki, pch = wyniki+1)
points(medoids[,c("RI", "Na")], pch = 16, cex = 1.5, col = 1:2)
```

Meh

Dokładność (matchedClasses): `r round(compareMatchedClasses(wyniki, Glass$Type)$diag*100, 2)`%.

```{r}
kable(Glass.copy[glass.pam7$id.med, ], caption="Dane medoidów, k=2")
```

#### AGNES

\newpage

```{r, fig.cap="AGNES: complete linage, k=2", cache = TRUE}
glass.agnes.complete <- agnes(x = glass.conf_mat,
                              diss = TRUE,
                              method = "complete")

fviz_dend(glass.agnes.complete, cex=0.4, k = 2)

wyniki <- cutree(glass.agnes.single, k = 2)
```

Tylko dla najdalszych sąsiadów, bo dał najlepsze wyniki.

Dokładność (matchedClasses): `r round(compareMatchedClasses(wyniki, Glass$Type)$diag*100, 2)`%.

#### DIANA

\newpage

```{r, fig.cap="DIANA, k=3", cache = TRUE}
glass.agnes.euclidean <- diana(x = glass.conf_mat,
                            diss = TRUE,
                            metric = "euclidean")

fviz_dend(glass.agnes.euclidean, cex=0.4, k = 3)

wyniki <- cutree(glass.agnes.euclidean, k = 3)
```

Dokładność (matchedClasses): `r round(compareMatchedClasses(wyniki, Glass$Type)$diag*100, 2)`%.

## Wnioski

# Podsumowanie

```{r, cache = TRUE}
end = Sys.time()
spend = end - start

total_seconds = as.numeric(spend, units = "secs")

minutes = floor(total_seconds / 60)
seconds = floor(total_seconds %% 60)
```

PS. Czas wykonywania kodu wynosi `r minutes` minut i `r seconds` sekund.